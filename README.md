# NLP_ass1_20200120_20200264_20201078

## Data:

1. USE any URL (e.g. Wikipedia),
2. Extract HTML from URL
3. Extract TEXT from HTML page e.g. (p or headings)
All 3 steps in python

## Processing on Data:

1. Cleaning data from each symbol or character doesnâ€™t contain to the data.
2. Normalization: make all the data to lower case
3. Tokenization: split the data to words
4. Lemmatization or Stemming: return each word to origin.
5. Stop words: remove stop words from the data.

## Unique Word: the output of the assignment to get all the unique words on the data.
